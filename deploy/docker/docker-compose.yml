services:
  #service 1
  postgres:
    container_name: postgres_container
    image: postgres:15
    environment:
      POSTGRES_USER: saurabh
      POSTGRES_PASSWORD: root
      TZ: Asia/Kolkata
      PGDATA: /data/postgres
    volumes:
      - postgresvol:/data/postgres
      - ./init-multi-db.sql:/docker-entrypoint-initdb.d/init.sql    #Mount the init-multi-db.sql file from my local directory into the container at /docker-entrypoint-initdb.d/init.sql, so it runs automatically when the database container starts for the first time
    ports:
      - "5432:5432"
    networks:
      - my-network
    restart: unless-stopped

  #service2
  pgadmin:
    container_name: pgadmin_container
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-sau@pagadmin.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadminvol:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - my-network
    restart: unless-stopped

  #service3
  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:4-management
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASSWORD: guest
    ports:
      - "5672:5672"     #RabbitMQ Message Broker
      - "15672:15672"     #RabbitMQ Management UI
    networks:
      - my-network
    restart: unless-stopped

  #service4
  keycloak:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:26.3.3
    ports:
      - "8443:8080"
    environment:
      KC_BOOTSTRAP_ADMIN_USERNAME: admin
      KC_BOOTSTRAP_ADMIN_PASSWORD: admin
    command: [ "start-dev" ]
    networks:
      - my-network

  #service5
#  zookeeper:
#    image: confluentinc/cp-zookeeper:7.5.0
#    container_name: zookeeper
#    ports:
#      - "2181:2181"
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#      ZOOKEEPER_TICK_TIME: 2000
#    networks:
#      - my-network

  #service6
#  kafka:
#    image: confluentinc/cp-kafka:7.5.0
#    container_name: kafka
#    ports:
#      - "9092:9092"
#    environment:
#      KAFKA_BROKER_ID: 1
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#    depends_on:
#      - zookeeper
#    networks:
#      - my-network

  #service7   zipkin service for distributed tracing
  zipkin:
    container_name: zipkin
    image: openzipkin/zipkin
    ports:
      - 9411:9411
    networks:
      - my-network      #from this network zipkin will collect the traces of services
      - loki            #from this network zipkin will allow configuration with grafana
    restart: unless-stopped


  #service8
  config-server:
    build: ../../configserver   # Build a Docker image using the Dockerfile in the ./configserver directory
    container_name: config-server
    ports:
      - 8888:8888
    networks:
      - my-network
    depends_on:
      - rabbitmq                        #service3 name
    environment:
      SPRING_CLOUD_CONFIG_SERVER_NATIVE_SEARCH_LOCATIONS: /config
      SPRING_PROFILES_ACTIVE: native
      RABBITMQ_HOST: ${RABBITMQ_HOST}   # Values automatically loaded from .env in current directory
      RABBITMQ_PORT: ${RABBITMQ_PORT}
      RABBITMQ_USERNAME: ${RABBITMQ_USERNAME}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
    volumes:
      - ../../configserver/src/main/resources/config:/config      #mount ./configserver/src/main/resources/config on /config folder


  #service9
  eureka:
    build: ../../eurekaServer   # Build a Docker image using the Dockerfile in the ./eurekaServer directory
    container_name: eureka
    ports:
      - 8761:8761
    networks:
      - my-network
    healthcheck:    #Without a health check, Docker only verifies whether the container itself is runningâ€”not whether the application inside it is actually healthy. To ensure the application is functioning properly, we need to define a health check.
      test: ["CMD", "wget", "--spider", "http://localhost:8761/actuator/health"]    #docker will run this command inside container every 10s,if it fails for 5 times then docker will mark this container as unhealthy
      interval: 10s
      timeout: 5s
      retries: 5


  #service10
  gateway-service:
    build: ../../gateway   # Build a Docker image using the Dockerfile in the ./gateway directory
    container_name: gateway-service
    ports:
      - 8080:8080
    environment:
      SPRING_PROFILES_ACTIVE: docker
    depends_on:
      - rabbitmq
      - eureka
      - keycloak
      - config-server
      - user-microservice
#      - product-microservice
    networks:
      - my-network



  #service11
  user-microservice:
    build: ../../user-microservice   # Build a Docker image using the Dockerfile in the ./user-microservice directory
    container_name: user-microservice
    mem_limit: 700m     #max 700MB only
    ports:
      - 8082:8082
    environment:
      SPRING_PROFILES_ACTIVE: docker
#      SPRING_CONFIG_IMPORT: optional:configserver:http://config-server:8888
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_BOOT_CONTEXT_CONFIG: DEBUG
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_CLOUD_CONFIG_CLIENT: DEBUG
      MONGO_URI: ${MONGO_URI}
      RABBITMQ_HOST: ${RABBITMQ_HOST}   # Values automatically loaded from .env in current directory
      RABBITMQ_PORT: ${RABBITMQ_PORT}
      RABBITMQ_USERNAME: ${RABBITMQ_USERNAME}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
    depends_on:
      - config-server
      - rabbitmq
      - eureka
      - keycloak
      - mongo
    networks:
      - my-network
    restart: on-failure


  #service12
#  product-microservice:
#    build: ../../product-microservice   # Build a Docker image using the Dockerfile in the ./product-microservice directory
#    container_name: product-microservice
#    ports:
#      - 8081:8081
#    environment:
#      SPRING_PROFILES_ACTIVE: docker
#      RABBITMQ_HOST: ${RABBITMQ_HOST}   # Values automatically loaded from .env in current directory
#      RABBITMQ_PORT: ${RABBITMQ_PORT}
#      RABBITMQ_USERNAME: ${RABBITMQ_USERNAME}
#      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
#      DB_USER: ${DB_USER}
#      DB_PASSWORD: ${DB_PASSWORD}
#    depends_on:
#      - rabbitmq
#      - eureka
#      - keycloak
#      - config-server
#      - pgadmin
#      - postgres
#    networks:
#      - my-network
#    restart: on-failure


  #service13
#  order-microservice:
#    build: ../../order-microservice   # Build a Docker image using the Dockerfile in the ./product-microservice directory
#    container_name: order-microservice
#    ports:
#      - 8083:8083
#    environment:
#      SPRING_PROFILES_ACTIVE: docker
#      RABBITMQ_HOST: ${RABBITMQ_HOST}   # Values automatically loaded from .env in current directory
#      RABBITMQ_PORT: ${RABBITMQ_PORT}
#      RABBITMQ_USERNAME: ${RABBITMQ_USERNAME}
#      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
#      DB_USER: ${DB_USER}
#      DB_PASSWORD: ${DB_PASSWORD}
#    depends_on:
#      - rabbitmq
#      - eureka
#      - keycloak
#      - config-server
#      - pgadmin
#      - postgres
#    networks:
#      - my-network
#    restart: on-failure


  #service14
  mongo:
    image: mongodb/mongodb-community-server:latest
    container_name: mongo
    ports:
      - "27018:27017"
    networks:
      - my-network

#-------------

  read:
    image: grafana/loki:latest
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ./logging/loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns
      loki:
        aliases:
          - loki

  write:
    image: grafana/loki:latest
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ./logging/loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  alloy:
    image: grafana/alloy:latest
    volumes:
      - ./logging/alloy-local-config.yaml:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ../../logs:/logs-parent:ro
    command:  run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy
    ports:
      - 12345:12345
    depends_on:
      - loki-gateway
    networks:
      - loki

  minio:
    image: minio/minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - loki

  prometheus:
    image: prom/prometheus:v2.44.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - loki

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    depends_on:
      - loki-gateway
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
          - name: Loki
            type: loki
            access: proxy
            url: http://loki-gateway:3100
            jsonData:
              httpHeaderName1: "X-Scope-OrgID"
            secureJsonData:
              httpHeaderValue1: "tenant1"
        EOF
        /run.sh
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ./grafana/datasources:/etc/grafana/provisioning/datasources   #prometheus and loki both will be picked up as datasource for grafana from - folder:/grafana/datasources.yml
    networks:
      - loki

  backend:
    image: grafana/loki:latest
    volumes:
      - ./logging/loki-config.yaml:/etc/loki/config.yaml
    ports:
      - "3100"
      - "7946"
    command: "-config.file=/etc/loki/config.yaml -target=backend -legacy-read-mode=false"
    depends_on:
      - loki-gateway
    networks:
      - loki


  loki-gateway:
    image: nginx:latest
    depends_on:
      - read
      - write
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1

        events {
          worker_connections   1000;
        }

        http {
          resolver 127.0.0.11;

          server {
            listen             3100;

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }

            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }

            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }

            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD", "service", "nginx", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - loki


  flog:
    image: mingrammer/flog
    command: -f json -d 200ms -l
    networks:
      - loki



#---------------


#Networks definition
networks:
  my-network:
    driver: bridge
  loki:
    driver: bridge

#Volumes definition
volumes:
  postgresvol:
  pgadminvol:

#--------------------------MySQL Docker Config
#services:
#  mysql:
#    container_name: mysql_container
#    image: mysql
#    environment:
#      MYSQL_ROOT_PASSWORD: root
#      MYSQL_DATABASE: productdb
#      MYSQL_USER: saurabh
#      MYSQL_PASSWORD: root
#    volumes:
#      - mysql_data:/var/lib/mysql
#    ports:
#      - "3307:3306"
#    networks:
#      - mysql-network
#    restart: unless-stopped
#
#  phpmyadmin:
#    container_name: phpmyadmin_container
#    image: phpmyadmin/phpmyadmin
#    environment:
#      PMA_HOST: mysql
#      PMA_PORT: 3306
#      MYSQL_ROOT_PASSWORD: root
#    ports:
#      - "8484:80"
#    networks:
#      - mysql-network
#    restart: unless-stopped
#
#networks:
#  mysql-network:
#    driver: bridge
#
#volumes:
#  mysql_data:
